"""
Agent J: Adversarial Critic (NEW)

A "Devil's Advocate" agent that finds flaws before the Dev Editor.
Uses gemini-2.5-pro to critically analyze drafts and provide structured feedback.

This agent does NOT write content - it only finds problems.

Uses the new unified Google GenAI SDK (google-genai).
"""

import os
import json
import time
from typing import Dict, List, Optional

# Use the new unified Google GenAI SDK
try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("Warning: google-genai not installed. Run: pip install google-genai")

from .schemas import (
    PipelineLogger, TodoTracker,
    save_markdown, load_json, read_file
)

AGENT_NAME = "AdversarialCritic"

# Gemini configuration - PRO for deep analysis
GEMINI_MODEL = "gemini-2.5-pro"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")


class AdversarialCritic:
    """
    Agent J: Adversarial Critic
    
    A "Devil's Advocate" that tries to find flaws in drafts before editing.
    
    Critique Dimensions:
    1. Clarity: Where is this explanation confusing?
    2. Consistency: Does terminology match previous chapters?
    3. Completeness: What key concepts from the source are missing?
    4. Accuracy: Does anything contradict the source material?
    
    Output: /ops/artifacts/critiques/*.json with structured feedback
    """
    
    SYSTEM_PROMPT = """××ª×” ××‘×§×¨ ××§×“××™ ×—××•×¨ (Adversarial Critic) ×œ×¡×¤×¨×™ ×œ×™××•×“.

×ª×¤×§×™×“×š: ×œ××¦×•× ×‘×¢×™×•×ª ×‘×˜×™×•×˜×” ×œ×¤× ×™ ×©×”×™× ×¢×•×‘×¨×ª ×œ×¢×¨×™×›×”.
××ª×” ×œ× ×›×•×ª×‘ ×ª×•×›×Ÿ - ×¨×§ ××•×¦× ×‘×¢×™×•×ª.

## ×××“×™ ×”×‘×™×§×•×¨×ª

### 1. ×‘×”×™×¨×•×ª (Clarity)
- ××™×¤×” ×”×”×¡×‘×¨ ××‘×œ×‘×œ?
- ××™×œ×• ××©×¤×˜×™× ××¨×•×›×™× ××“×™ ××• ××¡×•×¨×‘×œ×™×?
- ××™×¤×” ×—×¡×¨ ×”×§×©×¨ ×œ×§×•×¨× ××ª×—×™×œ?

### 2. ×¢×§×‘×™×•×ª (Consistency)
- ×”×× ×”××•× ×—×™× ×ª×•×××™× ××ª ×”×’×œ×•×¡×¨×™?
- ×”×× ×™×© ×¡×ª×™×¨×•×ª ×¤× ×™××™×•×ª ×‘×¤×¨×§?
- ×”×× ×”×¡×’× ×•×Ÿ ××—×™×“ ×œ××•×¨×š ×”×˜×§×¡×˜?

### 3. ×©×œ××•×ª (Completeness)
- ××™×œ×• ××•×©×’×™ ××¤×ª×— ×—×¡×¨×™×?
- ×”×× ×™×© "×§×¤×™×¦×•×ª" ×œ×•×’×™×•×ª?
- ×”×× ×›×œ ××˜×¨×ª ×”×œ××™×“×” ××›×•×¡×”?

### 4. ×“×™×•×§ (Accuracy)
- ×”×× ×™×© ×˜×¢× ×•×ª ×©×œ× × ×ª××›×•×ª ×‘××§×•×¨?
- ×”×× ×™×© ×”×’×–××•×ª ××• ×¤×™×©×•×˜×™ ×™×ª×¨?
- ×”×× ×”××¡×¤×¨×™× ×•×”× ×ª×•× ×™× × ×›×•× ×™×?

### 5. ×¤×“×’×•×’×™×” (Pedagogy)
- ×”×× ×™×© ××¡×¤×™×§ ×“×•×’×××•×ª?
- ×”×× ×¨××ª ×”×§×•×©×™ ××•×ª×××ª?
- ×”×× ×™×© "Hook" ××¢× ×™×™×Ÿ?

## ×—×•××¨×ª ×‘×¢×™×•×ª

- **critical**: ×—×™×™×‘ ×œ×ª×§×Ÿ ×œ×¤× ×™ ×¤×¨×¡×•× (×©×’×™××” ×¢×•×‘×“×ª×™×ª, ×¡×ª×™×¨×” ×—××•×¨×”)
- **major**: ××©×¤×™×¢ ××©××¢×•×ª×™×ª ×¢×œ ×”×œ××™×“×” (×‘×œ×‘×•×œ, ×—×•×¡×¨ ×©×œ××•×ª)
- **minor**: ×¨××•×™ ×œ×ª×™×§×•×Ÿ ××š ×œ× ×”×›×¨×—×™ (×¡×’× ×•×Ÿ, × ×™×¡×•×—)

## ×¤×œ×˜ × ×“×¨×©

×”×—×–×¨ JSON ×‘×¤×•×¨××˜:
{
  "chapter_id": "XX",
  "overall_assessment": "pass|needs_revision|reject",
  "confidence_score": 0.0-1.0,
  "critique_summary": "×¡×™×›×•× ×§×¦×¨ ×©×œ ×”×‘×¢×™×•×ª ×”×¢×™×§×¨×™×•×ª",
  "issues": [
    {
      "id": 1,
      "dimension": "clarity|consistency|completeness|accuracy|pedagogy",
      "severity": "critical|major|minor",
      "location": "## ×›×•×ª×¨×ª ××• ××¡×¤×¨ ×©×•×¨×”",
      "quote": "×”×¦×™×˜×•×˜ ×”×‘×¢×™×™×ª×™",
      "problem": "×ª×™××•×¨ ×”×‘×¢×™×”",
      "suggestion": "×”×¦×¢×” ×œ×ª×™×§×•×Ÿ"
    }
  ],
  "strengths": [
    "× ×§×•×“×ª ×—×•×–×§ 1",
    "× ×§×•×“×ª ×—×•×–×§ 2"
  ],
  "revision_priority": [
    "×ª×™×§×•×Ÿ 1 (×”×›×™ ×—×©×•×‘)",
    "×ª×™×§×•×Ÿ 2",
    "×ª×™×§×•×Ÿ 3"
  ]
}
"""
    
    def __init__(self, ops_dir: str, book_dir: str,
                 logger: PipelineLogger, todos: TodoTracker):
        self.ops_dir = ops_dir
        self.book_dir = book_dir
        self.logger = logger
        self.todos = todos
        self.drafts_dir = os.path.join(ops_dir, "artifacts", "drafts", "chapters")
        self.critiques_dir = os.path.join(ops_dir, "artifacts", "critiques")
        
        # Initialize Gemini client (new SDK)
        self.client = None
        if GEMINI_AVAILABLE and GEMINI_API_KEY:
            try:
                self.client = genai.Client(api_key=GEMINI_API_KEY)
                print(f"[{AGENT_NAME}] Gemini 3 Pro initialized (Adversarial Mode)")
            except Exception as e:
                print(f"[{AGENT_NAME}] Failed to initialize Gemini: {e}")
        else:
            print(f"[{AGENT_NAME}] No LLM available - skipping critique")
        
        os.makedirs(self.critiques_dir, exist_ok=True)
    
    def _generate(self, prompt: str) -> Optional[str]:
        """Generate content using the new Gemini SDK."""
        if not self.client:
            return None
        
        try:
            response = self.client.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,  # Lower for analytical thinking
                    max_output_tokens=8192,
                )
            )
            return response.text
        except Exception as e:
            print(f"[{AGENT_NAME}] Generation error: {e}")
            return None
        
    def run(self) -> Dict:
        """Execute the agent."""
        start_time = self.logger.log_start(AGENT_NAME)
        warnings = []
        output_files = []
        critiques = []
        
        if not self.client:
            print(f"[{AGENT_NAME}] Skipping - no LLM available")
            return {"critiques": [], "skipped": True}
        
        # Load chapter plan
        plan_path = os.path.join(self.ops_dir, "artifacts", "chapter_plan.json")
        chapter_plans = load_json(plan_path)
        
        print(f"[{AGENT_NAME}] Critiquing {len(chapter_plans)} drafts...")
        
        for plan in chapter_plans:
            chapter_id = plan["chapter_id"]
            
            # Load draft
            draft_path = os.path.join(self.drafts_dir, f"{chapter_id}_chapter_draft.md")
            if not os.path.exists(draft_path):
                warnings.append(f"No draft found for chapter {chapter_id}")
                continue
            
            content = read_file(draft_path)
            
            # Generate critique
            critique = self._critique_chapter(chapter_id, content, plan)
            critiques.append(critique)
            
            # Save critique
            critique_path = os.path.join(self.critiques_dir, f"chapter_{chapter_id}_critique.json")
            with open(critique_path, 'w', encoding='utf-8') as f:
                json.dump(critique, f, ensure_ascii=False, indent=2)
            output_files.append(critique_path)
            
            # Report status
            assessment = critique.get("overall_assessment", "unknown")
            num_issues = len(critique.get("issues", []))
            critical = sum(1 for i in critique.get("issues", []) if i.get("severity") == "critical")
            
            status_emoji = "âœ“" if assessment == "pass" else "âš " if assessment == "needs_revision" else "âœ—"
            print(f"[{AGENT_NAME}] {status_emoji} Chapter {chapter_id}: {assessment} ({num_issues} issues, {critical} critical)")
            
            time.sleep(5)  # Rate limiting
        
        # Generate summary report
        reports_dir = os.path.join(self.ops_dir, "reports")
        os.makedirs(reports_dir, exist_ok=True)
        report_path = os.path.join(reports_dir, "critique_summary.md")
        report_md = self._generate_summary_report(critiques)
        save_markdown(report_md, report_path)
        output_files.append(report_path)
        
        self.logger.log_end(AGENT_NAME, start_time, output_files, warnings)
        
        # Count chapters needing revision
        needs_revision = sum(1 for c in critiques if c.get("overall_assessment") != "pass")
        
        return {
            "critiques_dir": self.critiques_dir,
            "num_critiques": len(critiques),
            "needs_revision": needs_revision,
            "summary_report": report_path
        }
    
    def _critique_chapter(self, chapter_id: str, content: str, plan: Dict) -> Dict:
        """Generate adversarial critique for a chapter draft."""
        title = plan.get("hebrew_title", f"×¤×¨×§ {chapter_id}")
        
        prompt = f"""{self.SYSTEM_PROMPT}

---
×¤×¨×§: {chapter_id} - {title}

×˜×™×•×˜×” ×œ×‘×™×§×•×¨×ª:
{content}

---
×‘×¦×¢ ×‘×™×§×•×¨×ª ××¤×•×¨×˜×ª ×•×”×—×–×¨ JSON.
"""
        
        text = self._generate(prompt)
        
        if text:
            try:
                # Extract JSON
                json_start = text.find('{')
                json_end = text.rfind('}') + 1
                
                if json_start >= 0 and json_end > json_start:
                    critique = json.loads(text[json_start:json_end])
                    critique["chapter_id"] = chapter_id
                    return critique
            except Exception as e:
                print(f"[{AGENT_NAME}] Critique parsing failed for chapter {chapter_id}: {e}")
                self.todos.add(AGENT_NAME, f"chapter_{chapter_id}", f"Critique failed: {e}")
        
        # Return minimal critique on failure
        return {
            "chapter_id": chapter_id,
            "overall_assessment": "unknown",
            "confidence_score": 0.0,
            "critique_summary": "Critique generation failed",
            "issues": [],
            "strengths": [],
            "revision_priority": []
        }
    
    def _generate_summary_report(self, critiques: List[Dict]) -> str:
        """Generate summary report of all critiques."""
        md = "# ×“×•×— ×‘×™×§×•×¨×ª (Critique Summary)\n\n"
        md += f"*× ×•×¦×¨ ×¢×œ ×™×“×™ {AGENT_NAME}*\n\n"
        md += "---\n\n"
        
        # Overall stats
        total = len(critiques)
        passed = sum(1 for c in critiques if c.get("overall_assessment") == "pass")
        needs_rev = sum(1 for c in critiques if c.get("overall_assessment") == "needs_revision")
        rejected = sum(1 for c in critiques if c.get("overall_assessment") == "reject")
        
        md += "## ×¡×™×›×•× ×›×œ×œ×™\n\n"
        md += f"- **×¡×”\"×› ×¤×¨×§×™×**: {total}\n"
        md += f"- âœ… ×¢×‘×¨×•: {passed}\n"
        md += f"- âš ï¸ ×“×•×¨×©×™× ×ª×™×§×•×Ÿ: {needs_rev}\n"
        md += f"- âŒ × ×“×—×•: {rejected}\n\n"
        
        # Issue breakdown
        all_issues = []
        for c in critiques:
            for issue in c.get("issues", []):
                issue["chapter_id"] = c.get("chapter_id")
                all_issues.append(issue)
        
        critical = [i for i in all_issues if i.get("severity") == "critical"]
        major = [i for i in all_issues if i.get("severity") == "major"]
        minor = [i for i in all_issues if i.get("severity") == "minor"]
        
        md += "## ×”×ª×¤×œ×’×•×ª ×‘×¢×™×•×ª\n\n"
        md += f"- ğŸ”´ ×§×¨×™×˜×™×•×ª: {len(critical)}\n"
        md += f"- ğŸŸ  ××©××¢×•×ª×™×•×ª: {len(major)}\n"
        md += f"- ğŸŸ¢ ×§×œ×•×ª: {len(minor)}\n\n"
        
        # Critical issues list
        if critical:
            md += "## âš ï¸ ×‘×¢×™×•×ª ×§×¨×™×˜×™×•×ª ×œ×ª×™×§×•×Ÿ ××™×™×“×™\n\n"
            for issue in critical:
                chap = issue.get("chapter_id", "?")
                dim = issue.get("dimension", "?")
                prob = issue.get("problem", "?")
                md += f"- **×¤×¨×§ {chap}** [{dim}]: {prob}\n"
            md += "\n"
        
        # Per-chapter summary
        md += "## ×¤×™×¨×•×˜ ×œ×¤×™ ×¤×¨×§\n\n"
        
        for critique in critiques:
            chap = critique.get("chapter_id", "?")
            assessment = critique.get("overall_assessment", "?")
            summary = critique.get("critique_summary", "")
            issues = critique.get("issues", [])
            strengths = critique.get("strengths", [])
            
            emoji = "âœ…" if assessment == "pass" else "âš ï¸" if assessment == "needs_revision" else "âŒ"
            
            md += f"### {emoji} ×¤×¨×§ {chap}\n\n"
            md += f"**×”×¢×¨×›×”**: {assessment}\n\n"
            
            if summary:
                md += f"**×¡×™×›×•×**: {summary}\n\n"
            
            if strengths:
                md += "**× ×§×•×“×•×ª ×—×•×–×§**:\n"
                for s in strengths[:3]:
                    md += f"- {s}\n"
                md += "\n"
            
            if issues:
                md += f"**×‘×¢×™×•×ª** ({len(issues)}):\n"
                for issue in issues[:5]:
                    sev = issue.get("severity", "?")
                    dim = issue.get("dimension", "?")
                    prob = issue.get("problem", "?")[:100]
                    md += f"- [{sev}] {dim}: {prob}\n"
                md += "\n"
        
        md += "---\n\n"
        md += "*×”×¢×¨×”: ×™×© ×œ×ª×§×Ÿ ××ª ×›×œ ×”×‘×¢×™×•×ª ×”×§×¨×™×˜×™×•×ª ×œ×¤× ×™ ×¤×¨×¡×•×.*\n"
        
        return md
